# Part 1: Understanding the glibc Heap Implementation
from [Azeria Labs](https://azeria-labs.com/heap-exploitation-part-1-understanding-the-glibc-heap-implementation/)

Developers use moer stack-based exploit mitigations now, so attackers started building exploits using heap-related issues
	Ex: `use after free`, `double free`, `heap overflows`
Heap issues are often more difficult to understand
* attack techniques are dependent on how the heap allocator actually works

This series will explain how the heap works.
This post will introduce:
* What the heap is
* How new heap chunks are created
* Next post will go more into how chunks are freed and recycled

The way the heap works is very platform/implementation specific
* Many heap implementations exist
	* Google's `PortionAlloc`
	* `jemalloc` heap allocator used for FreeBSD
	* `glibc` is the default in Linux
* These are all very different
We'll be focusing on `glibc`'s heap allocator
* This is how heap allocations work for C/C++ programs on *Linux* devices by detault
* Derived from the `ptmalloc` heap implementation
	* Which itself is derived from the much older `dlmalloc` memory allocator
## What Is The Heap and Why Do People Use It?
The *heap* allows C and C++ programmers to manually allocate new regions of process memory during program execution.
* Calls to heap functions like `malloc` allow program to "ask" the heap manager to allocate these regions
* Allocated regions of memory (allocations) can be used, modified or referenced
* Then the allocations are returned to the heap manager via a call to `free`
#### Example: How a C program might allocate, use, and later free a structure on the heap:
```c
typedef struct 
{
    int field1;
    char* field2;
} SomeStruct;

int main()
{
    SomeStruct* myObject = (SomeStruct*)malloc(sizeof(SomeStruct));
    if(myObject != NULL)
    {
        myObject->field1 = 1234;
        myObject->field2 = “Hello World!”;
        do_stuff(myObject);
	free(myObject);
    }
    return 0;
}
```

As long as the programmer follows "rules", the heap manager ensures that the live allocations won't overlap.
* This feature makes the heap useful
	* Therefore, it's a very performance-sensitive feature of most C/C++ programs
### Heap Rules
These are some rules programmers must follow when using the heap, along with the vulnerabilities that may occur if a programmer violates these rules.
1) **Do not** read or write to a pointer returned by malloc after that pointer has been passed back to free
	This can lead to **use after free** issues.
	`Note`: This includes `malloc`-compatible functions like `realloc`, `calloc`, and `memalign`
2) **Do not** use or leak uninitialized information in a heap allocation.
	This can lead to **information leaks** or **uninitialized data** vulnerabilities.
	`Note`: `calloc` explicitly initializes allocations by zeroing them, so this one doesn't have this issue
3) **Do not** read or write bytes after the end of an allocation.
	This can lead to **heap overflow** and **read beyond bounds** vulnerabilities.
4) **Do not** pass a pointer that originated from `malloc` to `free` more than once.
	This can lead to **double free** vulnerabilities..
	`Note`: This includes `malloc`-compatible functions like `realloc`, `calloc`, and `memalign`
5) **Do not** read or write bytes before the beginning of an allocation
	This can lead to **heap underflow** vulnerabilities.
6) **Do not** pass a pointer that did not originate from `malloc` to `free`
	This can lead to **invalid free** vulnerabilities
	`Note`: This includes `malloc`-compatible functions like `realloc`, `calloc`, and `memalign`
	`Note`: `free(NULL)` is allowed and is not an invalid-free, but it does nothing
7) **Do not** use a pointer returned by malloc before checking if the function returned `NULL`
	This can lead to **null-dereference** bugs and *occasionally* **arbitrary write** vulnerabilities
	`Note`: This includes `malloc`-compatible functions like `realloc`, `calloc`, and `memalign`

Of course, `malloc` and `free` aren't the only way that C and C++ programmers interact with the heap
* C++ devs often allocate using C++ operators `new` and `new[]`
	* These allocations must be released using the corresponding `delete` and `delete[]` operators rather than with `free`
* Programmers can also allocate memory via malloc-compatible heap functions
	* Ex: `calloc`, `realoc`, and `memalign`
	* Like with `malloc`, these are eventually released via `free`
* For simplicity, we're discussing only `malloc` and `free`
	* Once we understand these, the others are pretty easy to understand
#### Example: How a C++ Program Might Allocate, Use, and Later Free a Structure on the Heap
```c++
class SomeClass
{
public:
    int field1;
    char* field2;
};

int main()
{
    SomeClass* myObject = new SomeClass();
    myObject->field1 = 1234;
    myObject->field2 = “Hello World!”;
    do_stuff(myObject);
    delete myObject;
    return 0;
}
```

## Memory Chunks and the Chunk Allocation Strategies

Suppose a programmer asks for 10 bytes of memory via `malloc`
* The heap manager needs to do more than just find a random 10 bytes somewhere
	* It must store metadata about the allocation
		* Metadata is stored alongside the 10-byte region that the programmer can use
	* Also needs to ensure the allocation will be aligned
		* Alignments:
			* 8-byte aligned on 32-bit systems
			* 16-byte aligned on 64-bit systems
		* Alignment has a big impact on the correctness and performance if the program stores complex data structures
			* It doesn't matter as much for simple data like a text string or byte array
			* Heap manager must default to making sure that allocations are aligned.

The allocation metadata and alignment-padding bytes are stored alongside the region of memory that `malloc` gives the program.
* For this reason, the heap manager internally allocates "*chunks*" of memory that are slightly larger than what the program asked for
	* Ex: If the program needs a a10-byte allocation:
		* the heap manager finds or creates a new *chunk* that fits:
			* the 10-byte space
			* metadata
			* alignment padding bytes
		* It marks the chunk as *allocated*,
		* Then the heap manager returns a pointer to the 10-byte "user data" region inside the *chunk*
			* This is the return value of the `malloc` call
###### Allocation Diagram
![[Pasted image 20240326113709.png]]
### Chunk Allocation: Basic Strategy
So...how does the heap manager internally allocate these chunks?

Lets look at a (simplified) strategy for allocating **small** chunks of memory
* This is the bulk of that the heap manager does
* Then we can look at large allocations
	* It's more of a special case
##### Simplified Allocation Strategy for Small Chunks
1) If there is a *previously-freed* chunk of memory **and** it is large enough to serve the request:
	The heap manager will use that *freed* chunk for the new allocation
2) **Otherwise**, if there is available space at the top of the heap:
	The heap manager will allocate a new chunk out of that available space
3) **Otherwise**, the heap manager will ask the kernel to add new memory at the end of the heap
	Then it allocates a new chunk from this newly allocated space
4) If all of this fails, the allocation can't be serviced
	Malloc will return `NULL`
### Allocating From *Freed* Chunks
Conceptually:
* As memory is passed back to `free`, the heap manager tracks these freed chunks in linked lists called *"bins"*
* When an allocation request is made:
	1)  The heap manager searches those bins for a free chunk large enough
	2) If it finds one:
		1) It removes the chunk from the *bin*
		2) Marks the chunk as *"allocated"*
		3) Returns a pointer to the *"user data"* portion of the hunk
			* This is the return value of *malloc*
* There are several different types of bins for performance reasons
	Ex: `fastbins`, `unsorted bin`, `small bins`, `large bins`, and the `per-thread tcache`
	* We'll talk about these in part two]
###### Heap When Allocating from Freed Chunks:
![[Pasted image 20240326115300.png]]

### Allocating From the Top of the Heap
This happens when there are no free chunks available
* Heap manager constructs a new chunk *"from scratch"*
To do this:
1) Heap manager looks at the free space at the end of the heap to see if there is enough space
	* This is often called the *"top chunk"* or the *"remainder chunk"*
2) If there is, the heap manager manufactures a new chunk out of this free space
###### Heap Before Allocation
![[Pasted image 20240326115617.png]]
###### Heap After Allocation
![[Pasted image 20240326115648.png]]

### Asking the Kernel for More Memory at the Top of the Heap
Once the free space at the top of the heap is used up, the heap manager has to ask the kernel to add more memory at the end of the heap.
	End of the heap == top of the heap bc it grows down

Heap manager calls `sbrk` to ask the kernel to allocate more memory
* This uses a system call called `brk` on most Linux-based systems
	* Name originally meant "change the program break location"
		* Complicated way to say "this thing ads more memory to the region just after where the program gets loaded into memory"
* Memory is allocated at the end of the program's initial heap
	* This is right after where the program is loaded into memory
###### Heap Before Allocation
![[Pasted image 20240326120225.png]]
###### Heap After Allocation
![[Pasted image 20240326120243.png]]

Eventually, expanding the heap with `sbrk` will fail
* The heap will grow too large
	* Expanding it further could cause it to collide with other things in the processes' address space
		* Memory mappings
		* Shared libraries
		* A thread's stack region
* When this happens, the heap manager will have to attach new *non-contiguous* memory to the initial heap
	* This uses calls to `mmap`
	* if `mmap` fails. the process can't allocate more memory
	
		* *malloc* will return `NULL`
### Off-Heap Allocations via MMAP
*Very large* allocation requests get get *"special treatment"* from the heap manager
* By default, the threshold for *"very large"* is 128 KB
	* Up to 512 KB on 32-bit systems
	* Up to 32 MB on 64-bit systems
	* This threshold can **increase dynamically** if the heap manager detects that these large allocations are being used *transiently*

### Arenas
On *multi-threaded* applications, the heap manager needs to defend the internal heap data structures from *race conditions* that could cause the program to crash
* The heap manager used to use a *global mutex* before every heap operation prior to `ptmalloc2`
	* This ensured only one thread could interact with the heap at any given time
	* Led to performance problems on applications with a bunch of threads
		* The heap allocator is very high-usage and performance sensitive
* `ptmalloc2` introduced *"arenas"*
	* Each *arena* is essentially an entirely different heap
		* *Arenas* manage their own chunk allocation and free *bins* completely separately
		* Each *arena* still serializes access to its own internal data structures with a *mutex*
		* Threads can safely perform heap operations without stalling each other
			* As long as they're interacting with different *arenas*
* *Single-threaded* applications only use one *arena*
	* This is the initial *"main arena"* of the program
		* It contains the heap as we've already seen it
* With each new thread that joins the process, the heap manager finds arenas that no other thread is using and attaches the available thread
	* As new threads join the process:
		* The heap manager allocates and attaches secondary arenas to each new thread
		* This reduces the chance that the thread will have to wait for other threads when attempting heap operations like `malloc` or `free`
* Once all available *arenas* are in use:
	* The heap manager creates a new one
		* Up to the maximum number of arenas:
			32-bit: `2 * [# CPU Cores]`
			64-bit: `8 * [# CPU Cores]`
	* Once the arena limit is reached, multiple threads must share an arena
But how do these *secondary arenas* even work?
* Earlier, we saw that the main heap is located right after where the program is loaded into memory (and expanded using `brk` system call)
	* This can't also be true for secondary arenas
* Secondary arenas emulate the behavior of the main heap using *"subheaps"*
	* These are created using `mmap` and `mprotect`

### Subheaps
*Subheaps* work about the same as the initial program heaps, but there are two main differences:
* Initial Program Heap
	* Located immediately after the program location in memory
	* Dynamically expanded by `sbrk`
* Subheaps
	* Positioned into memory using `mmap`
	* Heap manager manually emulates growing the subheap using `mprotect`
###### Subheap location in memory
![[Pasted image 20240326125121.png]]
#### Subheap Creation
When the heap manager creates a *subheap*, it calls `mmap` to ask the kernel to reserve a region of memory that the subheap can grow into
* It asks `mmap` for pages marked `PROT_NONE`
	* This indicates to the kernel that it only needs to reserve the address range for the region
		* Kernel doesn't need to attack memory to it yet
* Reserving this region **does not** directly allocate memory into the subheap
	* Really, it asks the kernel to refrain from allocating things (thread stacks, mmap regions, and other allocations) inside this region
* By default, the maximum size of a subheap (the region of memory reserved for a subheap to grow into)
		32-bit: 1 MB
		64-bit: 64 MB
###### Subheap Creation
![[Pasted image 20240326125251.png]]
#### Growing Subheaps
The heap manager emulates "growing" the subheap by manually invoking `mprotect`
* This is different than how the initial heap grows using `sbrk`
Invoking `mprotect` changes pages from `PROT_NONE` to `PROT_READ | PROT_WRITE`
* *This* causes the kernel to attach physical memory to those addresses
	* In effect, causing the subheap to slowly grow
	* Will grow until `mmap` region is full
* Once the subheap is exhausted, the arena just allocates another
	* Secondary arenas can keep growing almost indefinitely
		* Will eventually fail once the kernel runs out of memory or the process runs out of address space

#### To Recap:
The initial *"main arena"* contains only the *"main heap"*
* Main heap is stored right after where the program binary is stored in memory
* Main heap is expanded using `sbrk`
* This is the only arena used for *single-threaded* applications
On *multi-threaded applications*, new threads are given *secondary arenas* to allocate from
* Arena use speeds up the program by reducing the likelihood that threads need to wait before performing heap operations
* Secondary arenas allocate chunks from one (or more) *subheaps*
	* The heap manager calls `mmap` to allocate chunks from the *subheaps*
		* They're located elsewhere in memory
	* *subheaps* grow with calls to `mprotect`

### Chunk Metadata
So what we know now:
* How chunks get allocated
* That chunks contain:
	* *User Data* area
		* A pointer to which is given as the return value of `malloc`
	* Metadata
		* But what actually *is* this? What does it record? Where does it live?

The *exact layout* of chunk metadata is a bit weird
* The heap manager combines metadata at the end of one chunk with the metadata at the start of the next
	* Several metadata fields exist/are used depending on chunk characterists
###### For now we'll just look at *live allocations*
* Have a single `size_t` header positioned just behind the *user data* region
	* a `size_t` value is a 4 byte int on a 32-bit system and an 8-byte int on 64-bit
	* This field is written during `malloc`
		* Source code calls it `mchunk_size`
	* `free` uses it to decide how to handle the release of the allocation

![[Pasted image 20240326133433.png]]
###### `mchunk_size`
* Stores four pieces of information: chunk size, and three bits: `A`, `M`, `P`
	* These all fit in the same `size_t` field because chunk sizes are always 8 or 16-byte aligned
		* The low three bits will always be zero
	* `A Flag`: Indicates that the chunk belongs to a *secondary arena*
		* During free, the heap manager is only given a pointer to the allocation
			* It must find which arena the pointer belongs to
			* If `A` is set:
				the heap manager must search each arena to see if the pointer points to any of the arena's subheaps
			* If `A` is not set:
				The heap manager knows that it came from the initial area
	* `M Flag`: indicates that the chunk is a large allocation that was allocated off heap via `mmap`

The next part will talk about how free chunks are *"coalesced"* together then how chunks are allocated and recycled using different types of bins.
![[Pasted image 20240326141712.png]]

![[Pasted image 20240326141731.png]]

![[Pasted image 20240326141807.png]]

Then we'll go over heap vulnerabilities and how they can be exploited!

# Part 2: Understanding the glibc Heap Implementation
From [Azeria Labs](https://azeria-labs.com/heap-exploitation-part-2-glibc-heap-free-bins/)
## Recap of last part
Basic behavior of `malloc` and `free`
* `malloc` handles memory allocation requests by allocating memory *chunks*
* Each *chunk* stores:
	* *user data* region
		* `malloc` returns a pointer to this
	* *chunk* metadata
![[Pasted image 20240326142245.png]]

Basic heap manager chunk-allocation strategy:
* Saw how new chunks are created from the top of the heap when there are no already-freed chunks
###### Before Allocation
![[Pasted image 20240326142343.png]]
###### After Allocation
![[Pasted image 20240326142401.png]]

This post will go over how the chunk-recycling strategy works
* ie: how allocations passed back to `free` are saved and eventually recycled for future `malloc` requests
	* Lots of heap exploitation techniques rely on exploiting these mechanics

## How Does `free` Work?
When a program is finished with an allocation from `malloc`
1) The program releases it back to the heap manager by passing it to `free`
2) The heap manager resolves the pointer back to its corresponding chunk
##### Heap Manager Pointer Resolution
* The heap manager subtracts the size of the chunk metadata from the pointer that was passed to `free`
	* This only works bc the *user data* region lies inside the chunk
		* Is only valid if the pointer passed to `free` **really is** from a live allocation from `malloc`
		* Otherwise, the heap manager might release or recycle an invalid chunk
			* Could lead to memory corruption issues that cause a crash or help an attacker
			* To prevent this, the `free` does some checks to see if the freed pointer is valid
##### `free` Pointer Validation
The program will abort if any of these checks fail
1) Checks that the allocation is aligned on an 8-byte or 16-byte boundary
	* `malloc` ensures that all allocations are alligned
2) Checks that the *chunk*'s `size` field isn't impossible
	* Too small
	* Too large
	* Not an aligned size
	* Would overlap the end of the process' address space
3) Checks that the *chunk* lies within the boundaries of the *arena*
4) Checks that the chunk is not already marked as free
	* Check's the corresponding `P` in the metadata at the start of the next chunk

These checks aren't exhaustive
* a pointer to attacker-controlled data could potentially bypass these sanity checks
## `FREE` Chunk Metadata
Earlier we saw how *live chunks* store metadata alongside their *user data* region used by the program
* These live allocations store:
	* *chunk size*
	* `A` and `P` fields
		* They do not use the `M` field because a `mmap`-ed *chunk* will always be `munmap`-ed during `free` rather than turned into a free chunk for recycling
![[Pasted image 20240326143718.png]]

Free chunks store information **after** the *user data* region using *boundary tags*
* *Boundary Tags* carry size information before and after the *chunk*
* Allows *chunks* to be traversed starting from any known chunk and in any direction
	* Enables very fast *coalescing* of adjacent free *chunks*
Freed chunks are stored in the corresponding *"free bins"*
* *Free bins* operate as *linked lists*
* Requires each free chunk to also store pointers to other chunks
	* The heap manager repurposes the *user data* region to store this additional metadata

## Recycling Memory With Bins
Internally, the heap manager needs to keep track of freed chunks so that `malloc` can reuse them for allocations
* In a *"naive implementation"*, the heap manager could store all freed chinks together in a giant linked list
	* This would slow `malloc` down
* The heap manager maintains a series of lists called `bins`
	* Designed to maximize the speed of allocations and frees

### What are Bins
There are 5 types of bins
	62 *small bins*
	63 *large bins*
	1 *unsorted bin*
	10 *fastbins*
	64 *tcache bins*
(These numbers are per-thread)

The *small*, *large*, and *unsorted bins* are the oldest type of bin
* used to implement the *basic* recycling strategy
* *fastbins* and *tcache bins* are an optimization layer on top

*Small*, *large*, and *unsorted bins* are all in the same array
* Array set up in heap manager source code
```c
BIN[0] = N/A
BIN[1] = UNSORTED_BIN
BIN[2] - BIN[63] = SMALL_BIN
BIN[64] - BIN[126] = LARGE BIN
```

Remember the basic algorithm for `free`:
1) If the *chunk* has the `M` bit set in the metadata, the allocation was allocated *off-heap* and should be `munmap`-ed
2) Otherwise, if the chunk **before** this one is free, the chunk is merged backwards to create a larger free chunk
3) Similarly, if the chunk **after** this one is free, the chunk is merged forwards
4) If either of these potentially-larger chunks borders the *"top"* of the heap, the whole chink is absorbed into the end of the heap instead of stored in a *bin*
5) Otherwise, the chunk is marked *free* and stored in an appropriate *bin*

### Basic Recycling Strategies
#### Small Bins
These are the easiest *basic bin* to understand
There are **62** small bins that store chunks of the same size
* Ever chunk with `size < 512 bytes (32-bit)` or  `size < 1024 bytes (32-bit)` has a corresponding *small bin*
* Each small bin stores only one size of chunk
	* They are automatically ordered
	* Insertion/removal is very fast
![[Pasted image 20240326145617.png]]

#### Large Bins
We can't actually have a *bin* for every possible *chink size*
* Larger chunks go into *large bins*

Each of the **63** *large bins* operate mostly the same as small bins
* Store chunks within a size range rather than of a fixed size
	* There's no overlap: so each chunk corresponds to **exactly** one small or large bin
* Insertions must be manually sorted
	* Allocations from the list require traversing the list
	* Therefore, large bins are slower than small bins
		* They are used less frequently though
		* This is also why the large bin ranges are clustered towards smaller chunk sizes
			* The smallest *large bin* covers the 64-byte range from 512 bytes to 576 bytes
			* The second largest covers a size range of 256 kb
			* The largest covers all freed chunks above 1 MB

![[Pasted image 20240326150122.png]]

### Optimization Strategies
#### Unsorted Bin
The heap manager improves this basic algorithm by using an optimizing cache called the *"unsorted bin"*
* Calls to `free` are often clustered together and *frees* are often immediately followed by allocations of similarly sized chunks
	* Merging the freed chunks **before** saving the chunk to the correct bin will avoid some overhead
	* Allows for the fast return of recently freed allocations
* Heap manager coalesces newly freed chunks
	* Places in a general *unsorted* linked list
* `malloc` checks each item in the *unsorted bin* to see if it fits the request
	* If it does, `malloc` can use it immediately
	* If not, `malloc` puts it into its corresponding small or large bin
![[Pasted image 20240326150547.png]]

#### Fast Bins
Fast bins provide an even further layer of optimization
* bins keep recently released small chinks on a *"fast turnaround queue"*
	* Intentionally keeping the chunk live and **not** merging it
	* Chunks can be **immediately** repurposed if there's a need for that chunk size very soon after it is freed
Each fast bin is responsible for only a single fixed chunk size (like small bins!)
* 10 fast bins covering chunks of the following sizes +their metadata
	`16`, `24`, `32`, `40`, `48`, `56`, `64`, `72`, `80`, `88`
* Unlike small bins, fast bin chunks are never merged with their neighbors
	* The heap manager doesn't set the `P bit`
	* Conceptually, it's almost like **the heap manager doesn't *truly free* the chunk in fastbins**
* Insertions and removals are fast
	* Chunks are essentially "automatically" sorted like with smallbins
	* fast-binned chunks **never merge chunks**
		* So they can be stored in a *singly linked list*

So *fastbin* chunks are **never *"truly"* freed or merged**
* Could eventually cause the memory of the process to fragment and balloon over time
* Heap manager periodically *"consolidates"* the heap
	* This *"flushes"* each entry in the fast bin by "actually freeing" it
		* The chunk is merged with adjacent free chunks, then placed into the *unsorted bin* for `malloc` to use later
	* This happens when 
		* a `malloc` request is made that is larger than the *fastbin* can service
			* ie: Chunks over 512/1024 bytes
		* When freeing any chunk over 64 KB
		* When `malloc_trim` or `mallopt` are called

![[Pasted image 20240326154118.png]]

#### TCACHE (Per-Thread Cache) Bins
The final optimization that the heap manager uses is the *per-thread cache* (*tcache*) allocator
##### Race Conditions: The problem *tcache* is trying to solve
* Each process on a given computer system has one or more threads running at the same time
* Multiple threads allow a process to execute multiple concurrent operations
* Each thread in a given process shares the same address space - so they see the same code and data in memory
	* Each thread has its own registers and stack for temporary local variables
	* Global variables and the heap are shared between all of the threads

![[Pasted image 20240326155053.png]]

**Locks** prevent race conditions by forcing otherwise-simultaneous requests into a sequential queue
* one thread *"marks*" that it has taken ownership of a global resource before using it
	* It *marks* the resource as no-longer in use **after** its operation has completed
* If another thread needs the resource at the same time, it must wait until the other thread is done
	* This ensures the resource is only used by one thread at a time
	* The downside: *lock contention* - when a thread that is waiting on a resource stalls operations
		* This is an acceptable cost for many global variables, but it slows down the heap massively
##### Per Thread Caching
Each thread gets its own arena until it hits a threshold
* This speeds up allocations by having per-thread bins of small chunks ready and waiting
	* When a thread requests a chunk, the allocation can be serviced without waiting on a heap lock if there is a chunk available in the tcache
By default, each thread has 64 singly-linked *tcache bins*
* Each contains a max of 7 same-size chunks
	* Size ranges from:
		12 - 516 bytes on 32-bit systems
		24 - 1032 bytes on 64-bit systems
##### How do Chunks end up in tcache bins?
When a chunk is freed, the heap manager sees if it fits in a *tcache* bin corresponding to the chunk size
* Like *fastbins*, the *tcache bin* chunks are considered "in use" and are not merged with neighboring free chunks
* If the *tcache* for a that chunk size is full, the heap manager obtains the heap lock and then processes the chunk as usual

Corresponding *tcache* allocations are pretty straightforward
* If a requested chunk is available on a *tcache* bin, the heap returns that chunk without ever obtaining the heap lock
	* Otherwise, continue as before

Example Scenario:
* The program tries to make an allocation
	* There is a corresponding tcache bin **but** its full
* Time for a slightly-modified allocation strategy:
	* Heap manager takes the heap lock and *opportunistically promotes* as many chunks of that size as possible to the *tcache*
		* Up to the *tcache* bin limit of 7
		* Returns the **last** matching chunk to the user
## Putting it all together
Yay, now we understand the entire behavior of `malloc` and `free` in the *glibc* heap implementation
* and why each part of the algorithm exists

First, every allocation exists as a memory chunk
* It's aligned
* Contains metadata and a *user data* region
When a program requests memory from the heap
* The heap manager finds which chunk size the request corresponds to
* Then it searches for the memory

How the heap manager searches for memory to allocate
1) If the size corresponds with a 'tcache bin' **and** there is a *tcache* chunk available:
	Return that *tcache chunk* immediately
2) If the request is **enormous**:
	Allocate a chunk off-heap using `vmmap`
3) Otherwise, we obtain the arena heap lock and try the following:
	1) **Try the *fastbin*/*smallbin* recycling strategy**
		* If a corresponding *fast bin* exists, try to find a chunk from there
			* Also, *opportunistically prefill* the *tcache* with entries from the fast bin
		* Otherwise, if a corresponding *small bin* exists, allocate from there
			* Also *opportunistically prefill* the *tcache* as it goes
	2) **Resolve all of the *deferred frees***
		* "Truly free" entries in the *fastbins* and move their consolidated chunks to the *unsorted* bin
		* Heap manager goes through each entry in the *unsorted* bin
			* If it finds a suitable one, it stops
			* Otherwise, it puts the unsorted entry on it's corresponding *small/large* bin
				* Might possible *promote* small entries to *tcache* as it goes
	3) **Default back to the basic recycling strategy**
		* If the chunk size fits a large bin, search the corresponding large bin now
	4) **Create a new chunk from scratch**
		* Otherwise, there are no chunks available, so try to get one from the top of the heap
		* If the top of the heap is not big enough, extend it using `sbrk`
		* If the top of the heap can't be extended, create a discontinuous extension using `mmap`
	5) **If all else fails, return** `NULL`

Heap Manager *Free* Strategy
1) If the pointer is `NULL`, the C standard says "do nothing"
2) Otherwise, convert the pointer back to a chunk
	* The heap manager subtracts the size of the chunk metadata
3) Perform sanity checks on the chunk
	* aborts if they fail
4) If the chunk fits in the *tcache* bin, store it there
5) If the chunk has the `M` bit set, give it back to the OS by using `munmap`
6) Otherwise, it obtains the *arena heap lock* and:
	1) **If the chunk fits in a fastbin**
		* It puts it on the fatbin
	2) **If the chunk is >64 KB**
		* Consolidate the *fastbins* immediately
		* Put the resulting merged chunks on the *unsorted* bin
	3) **Merge the chunk backwards and forwards with neighboring freed chunks in the *small*, *large*, and *unsorted* bins**
	4) **If the resulting chunk is at the top of the heap**
		* Merge it into the top of the heap (instead of storing it in a bin)
	5) **Otherwise, store it in the *unsorted* bin**
		* `malloc` will later put the *unsorted bin* entries into the *small* or *large* bins